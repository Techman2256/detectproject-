{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f485cae",
   "metadata": {},
   "source": [
    "# Data Transform\n",
    "\n",
    "In this notebook, we will ask you a series of questions to evaluate your findings from your EDA. Based on your response & justification, we will ask you to also apply a subsequent data transformation. \n",
    "\n",
    "If you state that you will not apply any data transformations for this step, you must **justify** as to why your dataset/machine-learning does not require the mentioned data preprocessing step.\n",
    "\n",
    "The bonus step is completely optional, but if you provide a sufficient feature engineering step in this project we will add `1000` points to your Kahoot leaderboard score.\n",
    "\n",
    "You will write out this transformed dataframe as a `.csv` file to your `data/` folder.\n",
    "\n",
    "**Note**: Again, note that this dataset is quite large. If you find that some data operations take too long to complete on your machine, simply use the `sample()` method to transform a subset of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90a38922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load original data\n",
    "df = pd.read_csv(\"../data/bank_transactions.csv\")\n",
    "\n",
    "# Drop account identifiers\n",
    "df.drop(columns=[\"nameOrig\", \"nameDest\"], inplace=True)\n",
    "\n",
    "# One-hot encode the transaction type\n",
    "df = pd.get_dummies(df, columns=[\"type\"], drop_first=True)\n",
    "\n",
    "# Add engineered features\n",
    "df[\"balance_diff_orig\"] = df[\"oldbalanceOrg\"] - df[\"newbalanceOrig\"]\n",
    "df[\"balance_diff_dest\"] = df[\"newbalanceDest\"] - df[\"oldbalanceDest\"]\n",
    "\n",
    "# Optional: Drop isFlaggedFraud (it's not useful)\n",
    "df.drop(columns=[\"isFlaggedFraud\"], inplace=True)\n",
    "\n",
    "# Save cleaned file\n",
    "df.to_csv(\"transformed_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1360ca62",
   "metadata": {},
   "source": [
    "## Q1\n",
    "\n",
    "Does your model contain any missing values or \"non-predictive\" columns? If so, which adjustments should you take to ensure that your model has good predictive capabilities? Apply your data transformations (if any) in the code-block below.\n",
    "\n",
    "Yes the dataset does not contain missing values but it does contain non-predictive columns. Specifically, the columns nameOrig and nameDest are identifiers for accounts and do not contain any useful information for predicting fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cfe64ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      " amount               0\n",
      "oldbalanceOrg        0\n",
      "newbalanceOrig       0\n",
      "oldbalanceDest       0\n",
      "newbalanceDest       0\n",
      "isFraud              0\n",
      "type_CASH_OUT        0\n",
      "type_DEBIT           0\n",
      "type_PAYMENT         0\n",
      "type_TRANSFER        0\n",
      "balance_diff_orig    0\n",
      "balance_diff_dest    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop non-predictive identifier columns (safely)\n",
    "df.drop(columns=[\"nameOrig\", \"nameDest\"], inplace=True, errors='ignore')\n",
    "\n",
    "# Check again for missing values\n",
    "print(\"Missing values:\\n\", df.isnull().sum())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301be5ef",
   "metadata": {},
   "source": [
    "## Q2\n",
    "\n",
    "Do certain transaction types consistently differ in amount or fraud likelihood? If so, how might you transform the type column to make this pattern usable by a machine learning model? Apply your data transformations (if any) in the code-block below.\n",
    "\n",
    "Yes, certain transaction types consistently differ in both amount and fraud likelihood.\n",
    "Based on my EDA, the majority of fraudulent transactions occurred in the transfer and Cash_out types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb3dd3e",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b952403f",
   "metadata": {},
   "source": [
    "## Q3\n",
    "\n",
    "After exploring your data, you may have noticed that fraudulent transactions are rare compared to non-fraudulent ones. What challenges might this pose when training a machine learning model? What strategies could you use to ensure your model learns meaningful patterns from the minority class? Apply your data transformations (if any) in the code-block below.\n",
    "\n",
    "Answer here : Yes, fraudulent transactions are very rare, making up less than 0.2% of the dataset.\n",
    "This class imbalance makes it easy for models to ignore fraud altogether and just predict the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22f1422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud Class Distribution:\n",
      "isFraud\n",
      "0    0.998703\n",
      "1    0.001297\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Fraud Class Distribution:\")\n",
    "print(df[\"isFraud\"].value_counts(normalize=True))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17737e9e",
   "metadata": {},
   "source": [
    "## Bonus (optional)\n",
    "\n",
    "Are there interaction effects between variables (e.g., fraud and high amount and transaction type) that aren't captured directly in the dataset? Would it be helpful to manually engineer any new features that reflect these interactions? Apply your data transformations (if any) in the code-block below.\n",
    "\n",
    "Answer Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f48b7af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81cbfb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed dataset saved to transformed_data.csv\n"
     ]
    }
   ],
   "source": [
    "# write out newly transformed dataset to your folder\n",
    "\n",
    "df.to_csv(\"transformed_data.csv\", index=False)\n",
    "\n",
    "print(\"Transformed dataset saved to transformed_data.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
